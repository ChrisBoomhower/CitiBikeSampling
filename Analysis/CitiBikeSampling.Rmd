---
title: "MSDS 6370 Sampling Design"
output:
  html_notebook: default
---

#### Introduction
As interests in data science continue to accelerate, more and more organizations are joining the open data movement, releasing datasets to the open public. However, this may not always be the case and manual effort may be required to obtain the data by outsiders. In other instances, data may be made available but its shear volume may make it difficult for some individuals to gather the insights necessary given their computational resources available.

With these challenges in mind, we chose to assess survey sampling estimation methods while estimating mean CitiBike trip durations in NYC. The data utilized consists of [Citi Bike trip history data](https://www.citibikenyc.com/system-data) collected and released by NYC Bike Share, LLC and Jersey Bike Share, LLC under [Citi Bike's NYCBS Data Use Policy](https://www.citibikenyc.com/data-sharing-policy). Citi Bike is America's largest bike share program, with 10,000 bikes and 600 stations across Manhattan, Brooklyn, Queens, and Jersey City... 55 neighborhoods in all. As such, our data set's trip history includes all rental transactions conducted within the NYC Citi Bike system from July 1st, 2013 to February 28th, 2014. These transactions amount to 5,562,293 trips within this time frame.

For this particular dataset, the data is made available. However, since this may not always be the case, it represents a valid test case for applying various survey methods to estimate a population parameter. In our case, we first use Simple Random Sampling (SRS), Proportional Allocation, and Neyman Allocation to estimate trip duration mean, calculate the Design Effect (deff) for each complex method, obtain the new sample counts per the deff, and then proceed to compare each method's performance. After this, we transact 5 iterations of each of these sampling methodologies to derive confidence intervals for our estimation and compare these to the population true mean. 

#### Outlier Removal

Load necessary libraries

```{r}
require(survey)
require(dplyr)
require(lattice)
```

Pulling in data only if RDS file has not already been created.

```{r}
setwd("../Analysis/Data")
if(!file.exists("popData.rds")){
    pop.data <- NULL
    for(i in 1:length(list.files())){
        data.frag <- read.csv(paste("dataset",i,".csv",sep = ""), header = FALSE)
        pop.data <- rbind(pop.data, data.frag)
    }
    colnames(pop.data) <- c("tripduration",
                            "starttime",
                            "stoptime",
                            "start_station_id",
                            "start_station_name",
                            "start_station_latitude",
                            "start_station_longitude",
                            "end_station_id",
                            "end_station_name",
                            "end_station_latitude",
                            "end_station_longitude",
                            "bikeid",
                            "usertype",
                            "birth year",
                            "gender",
                            "LinearDistance",
                            "DayOfWeek",
                            "TimeOfDay",
                            "HolidayFlag",
                            "PRCP",
                            "SNOW",
                            "TAVE",
                            "TMAX",
                            "TMIN")
    saveRDS(pop.data, "popData.rds")
    rm(data.frag)
} else pop.data <- readRDS("popData.rds")
```

```{r}

    # BoxPlot tripDuration - Heavy Outliers!
boxplot(pop.data$tripduration)
    
    # How Many Greater than 24 hours?
print(nrow(pop.data[pop.data$tripduration>86400,]))

    # Remove > 24 Hours
pop.data <- pop.data[pop.data$tripduration<86400,c("tripduration", "DayOfWeek", "TimeOfDay")]

boxplot(pop.data$tripduration)

bwplot(tripduration ~ DayOfWeek, data = pop.data)
bwplot(tripduration ~ TimeOfDay | DayOfWeek, data = pop.data, scales=list(x=list(rot=45)))

trueMean <- mean(pop.data$tripduration)

print(paste0("The true mean of the population less outliers is: ", trueMean))

```

### Task 1
#### Stratified Sampling (Proportional Allocation)

First, we estimate the number of samples needed for a simple random sample(SRS) design. Although our goal is to perform a stratified sample for our estimate, we first need to compute a SRS design estimate to assist in calculation of design effect for the stratified design.

$n_{0,srs}=\frac{(Z_{\alpha/2}S)^2}{(moe)^2}=\frac{1.96^2 \times 1400.1478^2}{(15)^2}=33471.6752\approx33472$


Because the sample size is less than 10% of the original population, we may ignore the fpc adjustment performed in step 2, leaving us with a sample size of 33472.

```{r}
####Compute the sample size for a SRS
stdev = sd(pop.data$tripduration)
MOE   = 15 #seconds
N = nrow(pop.data)
print(stdev)
n0srs = ceiling((1.96^2*stdev^2)/(MOE^2))

print(paste0('With a sample size only ',round(n0srs/N*100,4), '% of the original population, we ignore fpc.'))

print(paste0('Sample Size needed for an estimate of the mean trip duration within 15 seconds, with 95% confidence, is ' , n0srs, '.'))

```

Compute Estimate using survey library with SRS and survey design of SRS 
```{r}
SrsMeanEstimate<-function(Seed, SampSize, printOutput= TRUE){
set.seed(Seed)

pop.data.SRSSampled = sample_n(pop.data,SampSize)

if(printOutput == TRUE){
  print(nrow(pop.data.SRSSampled))
  print(bwplot(tripduration ~ DayOfWeek, data = pop.data.SRSSampled))
  print(bwplot(tripduration ~ TimeOfDay | DayOfWeek, data = pop.data.SRSSampled, scales=list(x=list(rot=45))))
}

mydesign <- svydesign(id = ~1, data = pop.data.SRSSampled)

srsMean = svymean(~tripduration, design = mydesign)
srsSE = SE(srsMean)
srsCI = confint(srsMean)

rm(pop.data.SRSSampled)
rm(mydesign)

return(list(as.numeric(srsMean[1]),
            as.numeric(srsSE),
            as.numeric(srsCI[1]),
            as.numeric(srsCI[2])
           )
      )
}
```

```{r}
srsMean <- SrsMeanEstimate(n0srs, n0srs)
print(paste('The Mean Estimate =', srsMean[[1]]))
print(paste('The Standard Error =', srsMean[[2]]))
```

Compute Estimate using survey library with n<sub>0,srs</sub>, but use surveyDesign of Stratified Sample


```{r}
PropMeanEstimate<-function(Seed, SampSize, SampSizeAdj, printOutput= TRUE){

set.seed(Seed)

  # Identify Frequency of DayOfWeek Stratum
PropFreq <- as.data.frame(table(pop.data[,c("DayOfWeek", "TimeOfDay")]))
names(PropFreq)[1] = 'DayOfWeek'
PropFreq

PropFreq$N = nrow(pop.data)
PropFreq$p = PropFreq$Freq/PropFreq$N
PropFreq$SampSizeh = (PropFreq$p * SampSize)-SampSizeAdj  #adjustment of SampSizeAdj in order to round down the closest to .5 stratum due to an original rounded sample size 2 higher than n0srs
PropFreq$SampSizehRounded = round(PropFreq$SampSizeh)


pop.data.PropSampled <- NULL

for (i in 1:nrow(PropFreq)){
  pop.data.PropSampled<-rbind(pop.data.PropSampled,
                            sample_n(pop.data[(pop.data$DayOfWeek == PropFreq[i,"DayOfWeek"] 
                                                  & pop.data$TimeOfDay ==   PropFreq[i,"TimeOfDay"])
                                              ,]
                                     ,PropFreq[i,"SampSizehRounded"]
                                     )
                            )
                                
}

if(printOutput == TRUE){
  print(PropFreq)
  print(nrow(pop.data.PropSampled))
  print(bwplot(tripduration ~ DayOfWeek, data = pop.data.PropSampled))
  print(bwplot(tripduration ~ TimeOfDay | DayOfWeek, data = pop.data.PropSampled, scales=list(x=list(rot=45))))
}

mydesign <- svydesign(id = ~1, strata = ~paste(DayOfWeek,TimeOfDay), data = pop.data.PropSampled)

propMean = svymean(~tripduration, design = mydesign)
propSE = SE(propMean)
propCI = confint(propMean)

rm(pop.data.PropSampled)
rm(mydesign)
propCI = confint(propMean)
return(list(as.numeric(propMean[1]),
            as.numeric(propSE),
            as.numeric(propCI[1]),
            as.numeric(propCI[2])
           )
      )
}

```

```{r}
propMean <- PropMeanEstimate(n0srs, n0srs, .072)
print(paste('The Mean Estimate =', propMean[[1]]))
print(paste('The Standard Error =', propMean[[2]]))
```

Compute the Design Effect (SE stratified design / SE SRS Design)

$deff_{complex}=\frac{V(\bar{y}_{complex})}{V( \bar{y} {srs)})}=\frac{8.1176}{8.2137}=0.9883$

```{r}

deffProp = as.numeric(propMean[[2]]/srsMean[[2]])
deffProp

```

Compute appropriate Sample Size for Stratified Design Effect Modification (see 5.6 slides)
$n_{0,complex} = n_{0,srs} \times deff_{complex}= 33472 \times 0.9883 = 33080.25 \approx 33081$

```{r}
n0prop = n0srs*deffProp
n0prop
n0prop = ceiling(n0prop)
n0prop

```


Compute Proportional Allocation sample sizes amongst stratum
Utilize Sample Sizes to compute an Estimate of the mean, using Stratified Design with appropriate sample size

```{r}
propMean <- PropMeanEstimate(n0srs, n0prop, -.01)
print(paste('The Mean Estimate =', propMean[[1]]))
print(paste('The Standard Error =', propMean[[2]]))
```




#### Neyman Sampling Design
As our second sampling method, we choose to implement Neyman Allocation in order to account for *tripduration* variance by stratum. As was performed during Proportional Allocation, the strata sample sizes are computed such that the total number of samples equals our n<sub>0,srs</sub> calculated previously. The primary difference between our Proportional Allocation sampling calculations and Neyman Allocation computations is that our weight is derived from the product of stratum size and stratum standard deviation ($\frac{Nh \times Sh}{Total \space NhSh}$). Neyman sample count derivation steps are portrayed in the table output below.
```{r}
  # Identify Frequency of DayOfWeek Stratum
NeyFreq <- as.data.frame(table(pop.data[,c("DayOfWeek", "TimeOfDay")]))
names(NeyFreq)[1] = 'DayOfWeek'

stdDevs <- tapply(pop.data$tripduration, paste(pop.data$TimeOfDay, pop.data$DayOfWeek), sd)
NhSh <- NeyFreq$Freq * stdDevs
NhSh.ratio <- NhSh/sum(NhSh)
sampsRaw <- round(n0srs)*NhSh.ratio
Neyman.samples <- round(sampsRaw)

data.frame(NeyFreq,
           stdDevs = as.vector(stdDevs),
           NhSh = as.vector(NhSh),
           NhSh.ratio = as.vector(NhSh.ratio),
           sampsRaw = as.vector(sampsRaw),
           Neyman.samples = as.vector(Neyman.samples))
```
<br>
By rounding the calculated strata sample counts in our table output above, we now have definitive Neyman sample sizes for each stratum. To help validate these numbers' derivation, we compare their sum value against our previously calculated n<sub>0,srs</sub> value. The expectation is that their values should match since we multiplied strata weights by this value $(n_{0,srs} = 33472)$. However, our sum is just two samples larger than the n<sub>0,srs</sub> value. This is due to rounding error when deriving our whole number sample sizes from our raw, calculated sample sizes. Since our Neyman sample size is larger than the minimum calculated via n<sub>0,srs</sub>, no further action would normally be required; we are ensured our Neyman sample sizes will obtain for us an estimate with no more than 15 seconds margin of error (with 95% confidence). However, because our intent is to also calculate Design Effect, we choose to manually adjust our total sample count to match n<sub>0,srs</sub>.
```{r}
paste("n0srs = ", n0srs)
paste("Neyman Samples Total = ", sum(Neyman.samples))
```
<br>
When manually adjusting the sample count, we choose to find the two strata whose calculated sample size has the lowest decimal value over 0.5 and subtract one sample from their rounded sample counts. The two strata that meet this criterian are *Tuesday Evening* and *Sunday Afternoon* with values of 1929.5488 and 1100.5407 respectively. Therefore, we lower their rounded *Neyman.samples* by one to 1929 and 1100.

```{r}
paste("Sunday Afternoon before change: ", Neyman.samples[4])
Neyman.samples[4] = Neyman.samples[4] - 1
paste("Sunday Afternoon after change: ", Neyman.samples[4])

paste("Tuesday Evening before change: ", Neyman.samples[13])
Neyman.samples[13] = Neyman.samples[13] - 1
paste("Tuesday Evening after change: ", Neyman.samples[13])

paste("Neyman Samples Total = ", sum(Neyman.samples))
```
<br>
*In preparation for utilizing R's svydesign() library function, we next append these stratum sample counts to our dataset.*

```{r}
pop.data.Neyman <- data.frame(DayOfWeek = pop.data$DayOfWeek, TimeOfDay = pop.data$TimeOfDay, tripduration = pop.data$tripduration)
pop.data.Neyman$N <- NA

for(i in 1:nrow(NeyFreq)){
    pop.data.Neyman$N[paste(pop.data.Neyman$TimeOfDay, pop.data.Neyman$DayOfWeek) ==
                          attributes(Neyman.samples[i])] <- Neyman.samples[i]
}

head(pop.data.Neyman)
tail(pop.data.Neyman)
```
<br>
Our next task is to sample each stratum per our derived Neyman sample counts. We implement simple random sampling within each stratum, without replacement, to accomplish this. After doing so, we merge our original population stratum size counts with our sample data for comparison using R's *survey* library *svydesign()* function for mean estimation and standard error calculation.
```{r}
set.seed(n0srs)
pop.data.NeySampled <- NULL

for (i in 1:nrow(NeyFreq)){
  pop.data.NeySampled<-rbind(pop.data.NeySampled,
                            sample_n(pop.data.Neyman[paste(pop.data.Neyman$TimeOfDay,
                                                           pop.data.Neyman$DayOfWeek) ==
                                                         attributes(Neyman.samples[i]),],
                                     Neyman.samples[i]))

}
```

```{r}
NeySamp <- merge(pop.data.NeySampled, NeyFreq, by = c("TimeOfDay","DayOfWeek"))
```

With our Neyman sample set complete and population strata sizes merged, we are ready to apply R's *svydesign()* procedure for trip duration mean estimation. Running the function on our data produces a trip duration mean estimation of 870.75 seconds with 8.4397 seconds standard error. Again, our true population mean is 860.978 seconds, resulting in a delta of 9.772 seconds.
```{r}
  # Create SurveyDesign
mydesign <- svydesign(id = ~1, strata = ~paste(DayOfWeek,TimeOfDay), data = NeySamp) # Dropped since no correction needed: , fpc = ~Freq)

#mydesign <- postStratify(design = mydesign, strata = ~DayOfWeek, population = ToDFreq)

NeyMean <- svymean(~tripduration, design = mydesign)
NeyMean
```
As was performed for Proportional Allocation, we consider it important to calculate the Neyman Allocation Design Effect to acquire the correct total sample size necessary to produce results like SRS. Calculating Design Effect using SRS and Neyman Allocation SE values as follows results in a deff value of 1.0275.

$deff_{complex}=\frac{V(\bar{y}_{complex})}{V( \bar{y} {srs)})}=\frac{8.4397}{8.2137}=1.0275$

```{r}

deffNey = as.numeric(SE(NeyMean)/srsMean[[2]])
deffNey

```

Being that the deff value of 1.0275 is approximately 1.0 (only 2.8% larger), it is apparent that Neyman Allocation actually produces an estimate which is approximately the same as SRS and only slightly less precise (deff value may change slightly with each new random sample set but hovers around 1.0). Since the number reported leads us to believe a sample size 2.8% larger than n<sub>0,srs</sub> may be required for Neyman to obtain the same precision, we multiply n<sub>0,srs</sub> by 1.0275 to obtain our new total sample size.

$n_{0,complex} = n_{0,srs} \times deff_{complex}= 33472 \times 1.0275 = 34393.13 \approx 34394$

```{r}
n0Ney = n0srs*deffNey
n0Ney
n0Ney = ceiling(n0Ney)
n0Ney

```
<br>
With our new Neyman sample total defined, we proceed to compute our Neyman Allocation sample sizes amongst strata. This is performed as was done before Design Effect was calculated. The new strata sample size derivations are shown below.

```{r}
sample.Neyman <- function(seed.value){
    set.seed(seed.value)
    
      # Identify Frequency of DayOfWeek and TimeOfDay Stratum
    NeyFreq <- as.data.frame(table(pop.data[,c("DayOfWeek", "TimeOfDay")]))
    names(NeyFreq)[1] = 'DayOfWeek'
    
    stdDevs <- tapply(pop.data$tripduration, paste(pop.data$TimeOfDay, pop.data$DayOfWeek), sd)
    NhSh <- NeyFreq$Freq * stdDevs
    NhSh.ratio <- NhSh/sum(NhSh)
    sampsRaw <- round(n0Ney)*NhSh.ratio
    Neyman.samples <- round(sampsRaw)
    
    return(list(data.frame(NeyFreq,
               stdDevs = as.vector(stdDevs),
               NhSh = as.vector(NhSh),
               NhSh.ratio = as.vector(NhSh.ratio),
               sampsRaw = as.vector(sampsRaw),
               Neyman.samples = as.vector(Neyman.samples)),
           NeyFreq, Neyman.samples))
}
```

```{r}
Neyman.survey <- function(seed.value, Freq, Neyman.samples){
    set.seed(seed.value)
    
    pop.data.Neyman <- data.frame(DayOfWeek = pop.data$DayOfWeek, TimeOfDay = pop.data$TimeOfDay,
                                  tripduration = pop.data$tripduration)
    pop.data.Neyman$N <- NA
    
    for(i in 1:nrow(Freq)){
    pop.data.Neyman$N[paste(pop.data.Neyman$TimeOfDay, pop.data.Neyman$DayOfWeek) ==
                          attributes(Neyman.samples[i])] <- Neyman.samples[i]
    }
    
    pop.data.NeySampled <- NULL
    
    for (i in 1:nrow(Freq)){
      pop.data.NeySampled<-rbind(pop.data.NeySampled,
                                sample_n(pop.data.Neyman[paste(pop.data.Neyman$TimeOfDay,
                                                               pop.data.Neyman$DayOfWeek) ==
                                                             attributes(Neyman.samples[i]),],
                                         Neyman.samples[i]))
    
    }
    
    NeySamp <- merge(pop.data.NeySampled, Freq, by = c("TimeOfDay","DayOfWeek"))
    
      # Create SurveyDesign
    mydesign <- svydesign(id = ~1, strata = ~paste(DayOfWeek,TimeOfDay), data = NeySamp)
    
    NeyMean <- svymean(~tripduration, design = mydesign)
    
    NeySE = SE(NeyMean)
    
    NeyCI <- confint(svymean(~tripduration, design = mydesign))
    
    return(list(as.numeric(NeyMean[1]),
                as.numeric(NeySE),
                as.numeric(NeyCI[1]),
                as.numeric(NeyCI[2])))
}
```

```{r}
output <- sample.Neyman(n0srs)
NeymanSamps <- output[[1]]
NeyFreq <- output[[2]]
Neyman.samples <- output[[3]]

NeymanSamps

rm(output)
```

When again checking our *Neyman.samples* total against the Post-deff sample size calculated, we find that rounding error has again affected our total, this time resulting in a total one sample short (34393 instead of 34394). We identify the *Thursday Midday* stratum for rounding up since it contains the largest decimal value less than 0.5 (raw, calculated sample size is 798.4939). Its stratum sample size is manually updated to 799.

```{r}
paste("n0Ney = ", n0Ney)
paste("Post-Deff Neyman Samples Total = ", sum(Neyman.samples))
```

```{r}
paste("Thursday Midday before change: ", Neyman.samples[19])
Neyman.samples[19] = Neyman.samples[19] + 1
paste("Thursday Midday after change: ", Neyman.samples[19])
```
<br>
Finally, with new Neyman Allocation strata sample sizes calculated, we sample each stratum per its respective sample count and estimate the mean as was done previously. Doing so produces an estimate of 858.362 seconds with a standard error of 7.193.
```{r}
NeyMean <- Neyman.survey(n0srs, NeyFreq, Neyman.samples)

print(paste('The Mean Estimate =', NeyMean[[1]]))
print(paste('The Standard Error =', NeyMean[[2]]))
```


### Task 2 - Compare Confidence Intervals against 5 samples
#### Stratified Sampling (Proportional Allocation)
```{r}

SeedList <- c(10000, 20000, 30000, 40000, 50000)

df<- NULL

  #SRS Seed Executions
for (seed in SeedList){
  srsEstimate <- SrsMeanEstimate(seed, n0srs, FALSE)
  srsEstimate <- data.frame('SRS', seed, srsEstimate)
  names(srsEstimate) <- c("EstimateType","SeedValue", "MeanEstimate", "SE", "LCI", "UCI")
  df<- rbind(df,
             srsEstimate
            )
}

  #Prop Seed Executions
for (seed in SeedList){
  PropEstimate <- PropMeanEstimate(seed, n0prop, -.01, FALSE)
  PropEstimate <- data.frame('Prop', seed, PropEstimate)
  names(PropEstimate) <- c("EstimateType","SeedValue", "MeanEstimate", "SE", "LCI", "UCI")
  df<- rbind(df,
             PropEstimate
            )
}


 #Ney Seed Executions
for (seed in SeedList){
 NeyEstimate <- Neyman.survey(seed, NeyFreq, Neyman.samples)
 NeyEstimate <- data.frame('Ney', seed, NeyEstimate)
 names(NeyEstimate) <- c("EstimateType","SeedValue", "MeanEstimate", "SE", "LCI", "UCI")
 df<- rbind(df,
            NeyEstimate
           )
}

  #Add True Mean Value, in-line with estimates
df$TrueMeanValue <- trueMean

  #Add Bool Value for whether the Conf Limit contains the True Mean Value
df$WithinConfLimBool <- df$LCI <= df$TrueMeanValue & df$UCI >= df$TrueMeanValue

  #Print Results
print(df)


```
